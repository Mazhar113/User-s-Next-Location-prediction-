{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dependencies numpy and keras\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import np_utils\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc=pd.read_csv('data.csv')\n",
    "loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daydum = pd.get_dummies(loc.Day)\n",
    "loc = loc.join(daydum)\n",
    "loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc=loc.drop(['Day'],axis=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc['log_afternoon'].plot(figsize=(16,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc['lat_morning'].plot(figsize=(16,6))\n",
    "loc.rolling(window=30).mean()['lat_afternoon'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set=loc['lat_morning']\n",
    "training_set=pd.DataFrame(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "training_set_scaled = sc.fit_transform(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(5, 50):\n",
    "    X_train.append(training_set_scaled[i-5:i, 0])\n",
    "    y_train.append(training_set_scaled[i, 0])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "# Reshaping\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the first LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a third LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a fourth LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding the output layer\n",
    "regressor.add(Dense(units = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the RNN\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "# Fitting the RNN to the Training set\n",
    "regressor.fit(X_train, y_train, epochs = 100, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = regressor.evaluate(X_train, y_train, verbose=0)\n",
    "scores\n",
    "#print(\"%s: %.2f%%\" % (regressor.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = np.array([1/1/2021,25.430511,68.266920,25.416768,68.254553,24.847872,67.359835,1,0,0,0,0,0,0,0])\n",
    "x_input = x_input.reshape((1, 15))\n",
    "yhat = regressor.predict(x_input, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = pd.read_csv(path,index_col=\"Date\",parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = (np.random.randint(10, size=(100, 1)))\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "training_dataset_length = math.ceil(len(features) * .75)\n",
    "print(training_dataset_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale the all of the data to be values between 0 and 1 \n",
    "scaler = MinMaxScaler(feature_range=(0, 1)) \n",
    "scaled_data = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = scaled_data[0:training_dataset_length  , : ]\n",
    "\n",
    "#Splitting the data\n",
    "x_train=[]\n",
    "y_train = []\n",
    "\n",
    "for i in range(10, len(train_data)):\n",
    "    x_train.append(train_data[i-10:i,0])\n",
    "    y_train.append(train_data[i,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to numpy arrays\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "#Reshape the data into 3-D array\n",
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "# Initialising the RNN\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units = 50, return_sequences = True, input_shape = (x_train.shape[1], 1)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Adding a second LSTM layer and Dropout layer\n",
    "model.add(LSTM(units = 50, return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Adding a third LSTM layer and Dropout layer\n",
    "model.add(LSTM(units = 50, return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Adding a fourth LSTM layer and and Dropout layer\n",
    "model.add(LSTM(units = 50))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Adding the output layer\n",
    "# For Full connection layer we use dense\n",
    "# As the output is 1D so we use unit=1\n",
    "model.add(Dense(units = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile and fit the model on 30 epochs\n",
    "model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "model.fit(x_train, y_train, epochs = 30, batch_size = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test data set\n",
    "test_data = scaled_data[training_dataset_length - 10: , : ]\n",
    "\n",
    "#splitting the x_test and y_test data sets\n",
    "x_test = []\n",
    "y_test =  features[training_dataset_length : , : ] \n",
    "\n",
    "for i in range(10,len(test_data)):\n",
    "    x_test.append(test_data[i-10:i,0])\n",
    "    \n",
    "#Convert x_test to a numpy array \n",
    "x_test = np.array(x_test)\n",
    "\n",
    "#Reshape the data into 3-D array\n",
    "x_test = np.reshape(x_test, (x_test.shape[0],x_test.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check predicted values\n",
    "predictions = model.predict(x_test) \n",
    "#Undo scaling\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "\n",
    "#Calculate RMSE score\n",
    "rmse=np.sqrt(np.mean(((predictions- y_test)**2)))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
